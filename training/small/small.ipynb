{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pprint import pprint\n",
    "from IPython.display import display\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import e3nn\n",
    "import e3nn.point.data_helpers as dh \n",
    "from training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Tesla V100-PCIE-32GB\n",
      "True\n",
      "10.1\n"
     ]
    }
   ],
   "source": [
    "# make sure CUDA is available\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "device = \"cuda\"\n",
    "#torch.rand(10).to(device)\n",
    "#torch.rand(10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_elements = { \"H\", \"C\" }                            # only train on the shieldings at these elements\n",
    "elementwide_scaling_factors = {\"C\":5.0, \"H\":1.5, \"O\":50.0}  # divide absolute shieldings by these numbers\n",
    "n_elements = len(elementwide_scaling_factors)\n",
    "all_elements = list(elementwide_scaling_factors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represents the training data for one molecule\n",
    "class Molecule():\n",
    "    def __init__(self, name,               # name of molecule\n",
    "                 atomic_symbols,           # vector of strings of length n_atoms\n",
    "                 symmetrical_atoms,        # list of lists of 0-indexed atom numbers\n",
    "                 stationary_shieldings,    # vector of floats of length n_atoms\n",
    "                 geometries,               # (n_examples, n_atoms, 3)\n",
    "                 perturbed_shieldings):    # (n_examples, n_atoms, 1) \n",
    "        self.name = name                                       \n",
    "        self.stationary_shieldings = stationary_shieldings\n",
    "        self.geometries = geometries                                               \n",
    "        self.atomic_symbols = atomic_symbols\n",
    "        self.n_atoms = len(atomic_symbols)\n",
    "  \n",
    "        # rescale shieldings for training\n",
    "        perturbed_shieldings = perturbed_shieldings - stationary_shieldings\n",
    "        scaling_factors = [ elementwide_scaling_factors[symbol] for symbol in atomic_symbols ]\n",
    "        scaling_factors = np.array(scaling_factors)\n",
    "        self.scaling_factors = scaling_factors\n",
    "        perturbed_shieldings = perturbed_shieldings / scaling_factors\n",
    "        self.perturbed_shieldings = perturbed_shieldings\n",
    "        \n",
    "        # compute features\n",
    "        # one-hots for one example (since they're all the same): n_atoms, n_elements\n",
    "        features = []\n",
    "        for symbol in atomic_symbols:\n",
    "            inner_list = [ 1. if symbol == i else 0. for i in all_elements ]\n",
    "            features.append(inner_list)\n",
    "        self.features = np.array(features)\n",
    "    \n",
    "        # compute per-atom weights for the loss function\n",
    "        weights = [ 1.0 if symbol in relevant_elements else 0.0 for symbol in atomic_symbols ]\n",
    "        weights = np.array(weights)\n",
    "        for l in symmetrical_atoms:\n",
    "            weight = 1.0/len(l)\n",
    "            for i in l:\n",
    "                weights[i] = weight\n",
    "        self.weights = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a list of molecules, generate an MSE loss function that uses the weights:\n",
    "def generate_loss_function(molecules):\n",
    "    weights = [ m.weights for m in molecules ]\n",
    "    weights = np.concatenate(weights)\n",
    "    normalization = np.sum(weights)\n",
    "    weights = torch.from_numpy(weights).to(device)\n",
    "    normalization = torch.tensor([normalization]).to(device)\n",
    "    def loss_function(predictions, data):\n",
    "        predictions = output\n",
    "        observations = data.y\n",
    "        loss = (predictions-observations) * weights\n",
    "        loss = loss.square().sum() / normalization\n",
    "        loss = loss.sqrt()\n",
    "        return loss\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acetaldehyde\n",
      "acetone\n",
      "butanone\n",
      "dimethyl_ether\n",
      "ethane\n"
     ]
    }
   ],
   "source": [
    "molecules_dict = {}  # name -> Molecule\n",
    "\n",
    "# read the training data\n",
    "# iterate through the hdf5s (one per molecule)\n",
    "for hdf5_filename in sorted(glob(\"*.hdf5\")):\n",
    "    with h5py.File(hdf5_filename, \"r\") as h5:\n",
    "        name = h5.attrs.get(\"name\")\n",
    "        print(name)\n",
    "        geometries_and_shieldings = np.array(h5.get(\"data\"))\n",
    "        geometries = geometries_and_shieldings[:,:,:3]\n",
    "        perturbed_shieldings = geometries_and_shieldings[:,:,3]\n",
    "        stationary_shieldings = np.array(h5.attrs.get(\"stationary\"))\n",
    "        atomic_symbols = list(h5.get(\"atomic_symbols\"))\n",
    "        atomic_symbols = [ symbol.decode(\"utf-8\") for symbol in atomic_symbols ]\n",
    "        n_atoms = len(atomic_symbols)\n",
    "\n",
    "        # these are the 1-indexed atom numbers that are symmetrical\n",
    "        group = h5.get(\"symmetrical_atoms\")\n",
    "        symmetrical_atoms = []  # 0-indexed\n",
    "        for v in group.values():\n",
    "            v = [ i-1 for i in v ]\n",
    "            symmetrical_atoms.append(v)\n",
    "\n",
    "        # store the results\n",
    "        molecule = Molecule(name, atomic_symbols, symmetrical_atoms,\n",
    "                            stationary_shieldings, geometries, perturbed_shieldings)\n",
    "        molecules_dict[name] = molecule\n",
    "        \n",
    "molecules = np.array(list(molecules_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test molecules and generate functions for the training molecules\n",
    "training_molecules = molecules[[0,1,3,4]]\n",
    "testing_molecules = [molecules[2]]\n",
    "loss_function = generate_loss_function(training_molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features are one-hots for every atom,\n",
    "# so this is (number of one_hots, rank zero tensor, even parity)\n",
    "Rs_in = [(n_elements,0,1)]\n",
    "\n",
    "# we are outputing one scalar for every atom\n",
    "# so this is (one, rank zero tensor, even parity)\n",
    "Rs_out = [(1,0,1)]\n",
    "\n",
    "# maximum extent of radial basis functions in Angstroms\n",
    "max_radius = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the neighbor information for the train and test sets\n",
    "def create_torch_datasets(molecules, train_size, test_size, random_state):\n",
    "    training_dataset = []\n",
    "    testing_dataset = []\n",
    "    for molecule in molecules:\n",
    "        print(f\"Preprocessing {molecule.name} data:\")\n",
    "        train_geometries, test_geometries, train_shieldings, test_shieldings = train_test_split(\n",
    "                                                              molecule.geometries,\n",
    "                                                              molecule.perturbed_shieldings,\n",
    "                                                              train_size=train_size, test_size=test_size,\n",
    "                                                              random_state=random_state)\n",
    "        train_test = [(train_geometries,train_shieldings,training_dataset),\n",
    "                      (test_geometries,test_shieldings,testing_dataset)]\n",
    "        features = torch.tensor(molecule.features, dtype=torch.float64)\n",
    "        weights = torch.tensor(molecule.weights, dtype=torch.float64) \n",
    "        i = 0\n",
    "        n_to_save = len(train_geometries) + len(test_geometries)\n",
    "        for geometries, shieldings, target in train_test:\n",
    "            for g,s in zip(geometries,shieldings):\n",
    "                g = torch.tensor(g, dtype=torch.float64)\n",
    "                s = torch.tensor(s, dtype=torch.float64).unsqueeze(-1)  # [1,N]\n",
    "                data = dh.DataNeighbors(x=features, Rs_in=Rs_in, pos=g, r_max=max_radius,\n",
    "                                        self_interaction=True, name=molecule.name,\n",
    "                                        weights=weights, y=s, Rs_out = Rs_out)\n",
    "                target.append(data)\n",
    "                i += 1\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print(f\"{i+1:10d} of {n_to_save:10d}...\", end=\"\\r\", flush=True)\n",
    "                if i == n_to_save - 1:\n",
    "                    print(f\"{i+1:10d} of {n_to_save:10d}               done!\")\n",
    "    return training_dataset, testing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing acetaldehyde data:\n",
      "     15000 of      15000               done!\n",
      "Preprocessing acetone data:\n",
      "     15000 of      15000               done!\n",
      "Preprocessing dimethyl_ether data:\n",
      "     15000 of      15000               done!\n",
      "Preprocessing ethane data:\n",
      "     15000 of      15000               done!\n",
      "Preprocessing butanone data:\n",
      "      5001 of       5001               done!\n"
     ]
    }
   ],
   "source": [
    "training_dataset, test_dataset = create_torch_datasets(training_molecules,\n",
    "                                                       train_size = 10000,\n",
    "                                                       test_size = 5000,\n",
    "                                                       random_state = 1)\n",
    "_, final_testing_dataset = create_torch_datasets(testing_molecules,\n",
    "                                                 train_size = 1,\n",
    "                                                 test_size = 5000,\n",
    "                                                 random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network architecture\n",
    "model_kwargs = {\n",
    "    'network': 'GatedConvParityNetwork', \n",
    "    'conv': 'Convolution',\n",
    "    'Rs_in': Rs_in,            # shape of inputs\n",
    "    'Rs_out': Rs_out,          # shape of outputs\n",
    "    'mul': 5,                 # how many copies of each tensor at each layer\n",
    "    'lmax': 1,                 # maximum angular momentum\n",
    "    'layers': 5,               # number of layers\n",
    "    'max_radius': max_radius,  # radial kernel will extend out this far\n",
    "    'number_of_basis': 30,     # number of Gaussians in radial kernel\n",
    "}\n",
    "model = model_from_kwargs(model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "learning_rate = 3e-3\n",
    "opt = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "max_iter = 100       \n",
    "n_norm = 5           # n_norm is average number of convolution neighbors per atom\n",
    "batch_size = 100\n",
    "training_size = len(training_dataset)\n",
    "training_dataloader = tg.data.DataListLoader(training_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration     1    batch  2000 /  2000  loss =  3.962497    elapsed =  120.05 s\n",
      "Iteration     2    batch    94 /  2000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b337548b0693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m#print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/solvent/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/solvent/lib/python3.8/site-packages/e3nn/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/solvent/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/solvent/lib/python3.8/site-packages/e3nn/non_linearities/gated_block_parity.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, dim)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_gates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mnonscalars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonscalars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscalars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonscalars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/solvent/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/solvent/lib/python3.8/site-packages/e3nn/rs.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features_1, features_2)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_in1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_in2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [in1, in2, batch]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0mmixing_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sparse_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mixing_matrix\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [out, in1 * in2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model \n",
    "model.to(device)\n",
    "n_batches = int(training_size / batch_size)\n",
    "for i in range(max_iter):\n",
    "    start_time = time.time()\n",
    "    loss_cum = torch.tensor([0.]).to(device)\n",
    "    for j,data in enumerate(training_dataloader):\n",
    "        print(f\"Iteration {i+1:5d}    batch {j+1:5d} / {n_batches:5d}\", end=\"\\r\", flush=True)\n",
    "        data = tg.data.Batch.from_data_list(data)\n",
    "        data.to(device)\n",
    "        output = model(data.x, data.edge_index, data.edge_attr, n_norm=n_norm)\n",
    "        #print(output)\n",
    "        loss = loss_function(output, data)\n",
    "        #print(loss)\n",
    "        loss_cum += loss\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    end_time = time.time()\n",
    "    elasped_time = end_time - start_time\n",
    "    print(f\"Iteration {i+1:5d}    batch {j+1:5d} / {n_batches:5d}  loss = {loss_cum.item() / (j+1):9.6f}    elapsed = {elasped_time:7.2f} s\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   100 /   100\n",
      "Overall loss is 1.999474.  Evaluation took 3.01 s.\n"
     ]
    }
   ],
   "source": [
    "# test the model as it now\n",
    "torch.cuda.empty_cache()\n",
    "model.to(device)\n",
    "testing_dataloader = tg.data.DataListLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "testing_size = len(test_dataset)\n",
    "n_batches = int(testing_size / batch_size)\n",
    "results_dict = {} # molecule name -> residuals (n_examples,n_atoms)\n",
    "start_time = time.time()\n",
    "\n",
    "loss_cum = torch.tensor([0.]).to(device)\n",
    "for j,data in enumerate(testing_dataloader):\n",
    "    print(f\"batch {j+1:5d} / {n_batches:5d}\", end=\"\\r\", flush=True)\n",
    "    data = tg.data.Batch.from_data_list(data)\n",
    "    data.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, data.edge_index, data.edge_attr, n_norm=n_norm)\n",
    "        residuals = output - data.y\n",
    "        residuals = residuals.squeeze(-1).cpu().numpy()\n",
    "        i=0\n",
    "        for name in data.name:\n",
    "            molecule = molecules_dict[name]\n",
    "            n_atoms = molecule.n_atoms\n",
    "            scaling_factors = molecule.scaling_factors\n",
    "            if name not in results_dict:\n",
    "                results_dict[name] = []\n",
    "            subset = residuals[i:i+n_atoms] * scaling_factors\n",
    "            results_dict[name].append(subset)\n",
    "            i += n_atoms\n",
    "        loss = loss_function(output, data)\n",
    "    loss_cum += loss\n",
    "loss_cum = loss_cum/(j+1)\n",
    "end_time = time.time()\n",
    "elasped_time = end_time - start_time\n",
    "print(f\"\\nOverall loss is {loss_cum.item():.6f}.  Evaluation took {elasped_time:.2f} s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape residual data\n",
    "results_dict2 = {}\n",
    "for name,results in results_dict.items():\n",
    "    results = np.array(results).T\n",
    "    molecule = molecules_dict[name]\n",
    "    atomic_symbols = molecule.atomic_symbols\n",
    "    for i,v in enumerate(results):\n",
    "        element = atomic_symbols[i]\n",
    "        if element not in relevant_elements:\n",
    "            continue\n",
    "        label = f\"{name}_{element}{i+1}\"\n",
    "        results_dict2[label]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>range</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ethane_C1</th>\n",
       "      <td>-0.19</td>\n",
       "      <td>8.43</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethane_H2</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethane_H3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethane_H4</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethane_C5</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>7.47</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethane_H6</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethane_H7</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethane_H8</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimethyl_ether_C1</th>\n",
       "      <td>0.03</td>\n",
       "      <td>11.22</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimethyl_ether_H2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimethyl_ether_H3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimethyl_ether_H4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimethyl_ether_C5</th>\n",
       "      <td>0.08</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimethyl_ether_H6</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimethyl_ether_H7</th>\n",
       "      <td>0.03</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimethyl_ether_H8</th>\n",
       "      <td>0.05</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetone_C1</th>\n",
       "      <td>0.92</td>\n",
       "      <td>14.15</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetone_C3</th>\n",
       "      <td>-0.82</td>\n",
       "      <td>10.94</td>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetone_H4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetone_H5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetone_H6</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetone_C7</th>\n",
       "      <td>-0.79</td>\n",
       "      <td>8.37</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetone_H8</th>\n",
       "      <td>0.05</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetone_H9</th>\n",
       "      <td>0.05</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetone_H10</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetaldehyde_C1</th>\n",
       "      <td>2.39</td>\n",
       "      <td>15.38</td>\n",
       "      <td>9.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetaldehyde_C3</th>\n",
       "      <td>-0.65</td>\n",
       "      <td>6.86</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetaldehyde_H4</th>\n",
       "      <td>0.06</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetaldehyde_H5</th>\n",
       "      <td>0.06</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetaldehyde_H6</th>\n",
       "      <td>0.08</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetaldehyde_H7</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean  range  RMSE\n",
       "ethane_C1         -0.19   8.43  1.15\n",
       "ethane_H2         -0.00   0.89  0.01\n",
       "ethane_H3          0.00   0.99  0.01\n",
       "ethane_H4         -0.01   1.05  0.02\n",
       "ethane_C5         -0.17   7.47  1.07\n",
       "ethane_H6         -0.01   0.92  0.01\n",
       "ethane_H7         -0.00   0.91  0.02\n",
       "ethane_H8         -0.01   1.15  0.01\n",
       "dimethyl_ether_C1  0.03  11.22  1.27\n",
       "dimethyl_ether_H2  0.05   1.18  0.04\n",
       "dimethyl_ether_H3  0.06   2.33  0.04\n",
       "dimethyl_ether_H4  0.05   2.58  0.03\n",
       "dimethyl_ether_C5  0.08   7.30  1.11\n",
       "dimethyl_ether_H6  0.04   1.10  0.03\n",
       "dimethyl_ether_H7  0.03   1.04  0.03\n",
       "dimethyl_ether_H8  0.05   1.97  0.03\n",
       "acetone_C1         0.92  14.15  3.63\n",
       "acetone_C3        -0.82  10.94  2.11\n",
       "acetone_H4         0.04   1.44  0.04\n",
       "acetone_H5         0.05   1.23  0.04\n",
       "acetone_H6        -0.03   3.05  0.05\n",
       "acetone_C7        -0.79   8.37  2.00\n",
       "acetone_H8         0.05   2.15  0.05\n",
       "acetone_H9         0.05   1.48  0.04\n",
       "acetone_H10       -0.04   2.32  0.04\n",
       "acetaldehyde_C1    2.39  15.38  9.44\n",
       "acetaldehyde_C3   -0.65   6.86  1.70\n",
       "acetaldehyde_H4    0.06   1.66  0.04\n",
       "acetaldehyde_H5    0.06   2.52  0.05\n",
       "acetaldehyde_H6    0.08   1.76  0.05\n",
       "acetaldehyde_H7   -0.07   1.84  0.07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summary stats\n",
    "df = pd.DataFrame(results_dict2)\n",
    "means = df.mean()\n",
    "ranges = df.max()-df.min()\n",
    "RMSEs = df.pow(2).mean()\n",
    "df = pd.concat([means,ranges,RMSEs], axis=1)\n",
    "df.columns = [\"mean\",\"range\",\"RMSE\"]\n",
    "df = df.round(2)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def save_dataset(geometry_subset, shielding_subset, features_subset, output_filename):\n",
    "    dataset = []\n",
    "    n_to_save = len(geometry_subset)\n",
    "    print(f\"Preprocessing for {output_filename}:\")\n",
    "    for i,(g,s,f) in enumerate(zip(geometry_subset, shielding_subset, feature_subset)):\n",
    "        g,s,f = torch.tensor(g, dtype=torch.float64), torch.tensor(s, dtype=torch.float64).unsqueeze(-1), torch.tensor(f, dtype=torch.float64)\n",
    "        data = DataNeighborsSelection(x=f, Rs_in=Rs_in, pos=g, r_max=max_radius,\n",
    "                                      atomic_numbers=atomic_numbers, relevant_atomic_numbers=relevant_atomic_numbers,\n",
    "                                      y=s, Rs_out=Rs_out)\n",
    "        dataset.append(data)\n",
    "        if (i+1) % 100 == 0 or i == n_to_save - 1:\n",
    "            print(f\"{i+1:10d} of {n_to_save:10d}...\", end=\"\\r\", flush=True)\n",
    "    print(\"\\nWriting to disk...\", end=\"\", flush=True)\n",
    "    torch.save(dataset, output_filename)\n",
    "    print(f\"done.  Saved {len(dataset)} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataNeighborsSelection(dh.DataNeighbors):\n",
    "    # this class precomputes data for one training or test example\n",
    "    # x              : features (one-hots)\n",
    "    # Rs_in          : input classification [(number of tensors, tensor_rank, parity)\n",
    "    # pos            : geometry ([xyz])\n",
    "    # atomic_symbols : list of strings\n",
    "    # weights        : relative weight for RMSE calculation (deals with symmetrical atoms)\n",
    "    def __init__(self, x, Rs_in, pos, r_max, atomic_symbols, weights, self_interaction=True, **kwargs):\n",
    "        super().__init__(x, Rs_in, pos, r_max,\n",
    "                         self_interaction=self_interaction,\n",
    "                         relevant_atom_indices=relevant_atom_indices,\n",
    "                         weights=weights,\n",
    "                         **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def save_dataset(geometry_subset, shielding_subset, features_subset, output_filename):\n",
    "    dataset = []\n",
    "    n_to_save = len(geometry_subset)\n",
    "    print(f\"Preprocessing for {output_filename}:\")\n",
    "    for i,(g,s,f) in enumerate(zip(geometry_subset, shielding_subset, feature_subset)):\n",
    "        g,s,f = torch.tensor(g, dtype=torch.float64), torch.tensor(s, dtype=torch.float64).unsqueeze(-1), torch.tensor(f, dtype=torch.float64)\n",
    "        data = DataNeighborsSelection(x=f, Rs_in=Rs_in, pos=g, r_max=max_radius,\n",
    "                                      atomic_numbers=atomic_numbers, relevant_atomic_numbers=relevant_atomic_numbers,\n",
    "                                      y=s, Rs_out=Rs_out)\n",
    "        dataset.append(data)\n",
    "        if (i+1) % 100 == 0 or i == n_to_save - 1:\n",
    "            print(f\"{i+1:10d} of {n_to_save:10d}...\", end=\"\\r\", flush=True)\n",
    "    print(\"\\nWriting to disk...\", end=\"\", flush=True)\n",
    "    torch.save(dataset, output_filename)\n",
    "    print(f\"done.  Saved {len(dataset)} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features are one-hots for every atom,\n",
    "# so this is (number of one_hots, rank zero tensor, even parity)\n",
    "Rs_in = [(n_one_hots,0,1)]\n",
    "\n",
    "# we are outputing one scalar for every atom\n",
    "# so this is (one, rank zero tensor, even parity)\n",
    "Rs_out = [(1,0,1)]\n",
    "\n",
    "# maximum extent of radial basis functions in Angstroms\n",
    "max_radius = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a subset of the data to a .torch file\n",
    "# precompute the relevant neighbors\n",
    "relevant_atomic_numbers = [1, 6]\n",
    "\n",
    "def save_dataset(geometry_subset, shielding_subset, feature_subset, output_filename):\n",
    "    dataset = []\n",
    "    n_to_save = len(geometry_subset)\n",
    "    print(f\"Preprocessing for {output_filename}:\")\n",
    "    for i,(g,s,f) in enumerate(zip(geometry_subset, shielding_subset, feature_subset)):\n",
    "        g,s,f = torch.tensor(g, dtype=torch.float64), torch.tensor(s, dtype=torch.float64).unsqueeze(-1), torch.tensor(f, dtype=torch.float64)\n",
    "        data = DataNeighborsSelection(x=f, Rs_in=Rs_in, pos=g, r_max=max_radius,\n",
    "                                      atomic_numbers=atomic_numbers, relevant_atomic_numbers=relevant_atomic_numbers,\n",
    "                                      y=s, Rs_out=Rs_out)\n",
    "        dataset.append(data)\n",
    "        if (i+1) % 100 == 0 or i == n_to_save - 1:\n",
    "            print(f\"{i+1:10d} of {n_to_save:10d}...\", end=\"\\r\", flush=True)\n",
    "    print(\"\\nWriting to disk...\", end=\"\", flush=True)\n",
    "    torch.save(dataset, output_filename)\n",
    "    print(f\"done.  Saved {len(dataset)} records.\")\n",
    "    \n",
    "# splits the dataset randomly into training and test sets\n",
    "# train_size = # number of training examples\n",
    "# test_size = # number of test examples\n",
    "# prefix = filenames will start with this string\n",
    "# random_state = for reproducible splits\n",
    "def split_and_save(train_size, test_size, prefix, random_state):\n",
    "    assert train_size + test_size <= n_examples\n",
    "    #[ training_geometries, training_shieldings, training_features,\n",
    "    #  testing_geometries, testing_shieldings, testing_features     ]\n",
    "    splitting = train_test_split(geometries, shieldings, features,\n",
    "                                test_size = test_size, train_size = train_size,\n",
    "                                random_state = random_state, shuffle = True)\n",
    "    save_dataset(*splitting[::2], f\"{prefix}-train.torch\")\n",
    "    save_dataset(*splitting[1::2], f\"{prefix}-test.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing for acetone-split1-train.torch:\n",
      "      1000 of       1000...\n",
      "Writing to disk...done.  Saved 1000 records.\n",
      "Preprocessing for acetone-split1-test.torch:\n",
      "      5000 of       5000...\n",
      "Writing to disk...done.  Saved 5000 records.\n"
     ]
    }
   ],
   "source": [
    "train_size = 1000\n",
    "test_size = 5000\n",
    "split_and_save(train_size, test_size, \"acetone-split1\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = torch.load(\"acetone-split1-train.torch\")\n",
    "dataset2 = torch.load(\"acetone-split1-test.torch\")\n",
    "batch_size = 50\n",
    "train_dataloader = tg.data.DataListLoader(dataset1, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = tg.data.DataListLoader(dataset2, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network architecture\n",
    "model_kwargs = {\n",
    "    'network': 'GatedConvParityNetwork', \n",
    "    'conv': 'Convolution',\n",
    "    'Rs_in': Rs_in,            # shape of inputs\n",
    "    'Rs_out': Rs_out,          # shape of outputs\n",
    "    'mul': 5,                 # how many copies of each tensor at each layer\n",
    "    'lmax': 1,                 # maximum angular momentum\n",
    "    'layers': 5,               # number of layers\n",
    "    'max_radius': max_radius,  # radial kernel will extend out this far\n",
    "    'number_of_basis': 10,     # number of Gaussians in radial kernel\n",
    "}\n",
    "model = model_from_kwargs(model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "learning_rate = 3e-3\n",
    "opt = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "max_iter = 100       \n",
    "n_norm = 5           # n_norm is average number of convolution neighbors per atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(output, data):\n",
    "    index = data.relevant_atom_index\n",
    "    predictions = output[index]\n",
    "    observations = data.y[index]\n",
    "    loss = (predictions-observations).square().mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration     1    batch    20 /    20  loss = 0.542264    elapsed =    4.25 s\n",
      "Iteration     2    batch    20 /    20  loss = 0.183491    elapsed =    4.25 s\n",
      "Iteration     3    batch    20 /    20  loss = 0.102706    elapsed =    4.22 s\n",
      "Iteration     4    batch    20 /    20  loss = 0.040474    elapsed =    4.24 s\n",
      "Iteration     5    batch    20 /    20  loss = 0.030098    elapsed =    4.23 s\n",
      "Iteration     6    batch    20 /    20  loss = 0.029470    elapsed =    4.25 s\n",
      "Iteration     7    batch    20 /    20  loss = 0.025776    elapsed =    4.22 s\n",
      "Iteration     8    batch    20 /    20  loss = 0.022495    elapsed =    4.23 s\n",
      "Iteration     9    batch    20 /    20  loss = 0.021087    elapsed =    4.23 s\n",
      "Iteration    10    batch    20 /    20  loss = 0.021325    elapsed =    4.22 s\n",
      "Iteration    11    batch    20 /    20  loss = 0.020373    elapsed =    4.21 s\n",
      "Iteration    12    batch    20 /    20  loss = 0.018608    elapsed =    4.23 s\n",
      "Iteration    13    batch    20 /    20  loss = 0.019047    elapsed =    4.23 s\n",
      "Iteration    14    batch    20 /    20  loss = 0.018659    elapsed =    4.24 s\n",
      "Iteration    15    batch    20 /    20  loss = 0.016934    elapsed =    4.25 s\n",
      "Iteration    16    batch    20 /    20  loss = 0.016717    elapsed =    4.24 s\n",
      "Iteration    17    batch    20 /    20  loss = 0.016146    elapsed =    4.25 s\n",
      "Iteration    18    batch    20 /    20  loss = 0.014342    elapsed =    4.22 s\n",
      "Iteration    19    batch    20 /    20  loss = 0.014101    elapsed =    4.23 s\n",
      "Iteration    20    batch    20 /    20  loss = 0.015087    elapsed =    4.24 s\n",
      "Iteration    21    batch    20 /    20  loss = 0.013995    elapsed =    4.24 s\n",
      "Iteration    22    batch    20 /    20  loss = 0.012659    elapsed =    4.23 s\n",
      "Iteration    23    batch    20 /    20  loss = 0.012084    elapsed =    4.23 s\n",
      "Iteration    24    batch    20 /    20  loss = 0.010816    elapsed =    4.44 s\n",
      "Iteration    25    batch    20 /    20  loss = 0.011002    elapsed =    4.39 s\n",
      "Iteration    26    batch    20 /    20  loss = 0.011160    elapsed =    4.30 s\n",
      "Iteration    27    batch    20 /    20  loss = 0.009173    elapsed =    4.22 s\n",
      "Iteration    28    batch    20 /    20  loss = 0.008660    elapsed =    4.31 s\n",
      "Iteration    29    batch    20 /    20  loss = 0.010486    elapsed =    4.31 s\n",
      "Iteration    30    batch    20 /    20  loss = 0.009117    elapsed =    4.28 s\n",
      "Iteration    31    batch    20 /    20  loss = 0.009415    elapsed =    4.27 s\n",
      "Iteration    32    batch    20 /    20  loss = 0.008866    elapsed =    4.27 s\n",
      "Iteration    33    batch    20 /    20  loss = 0.008029    elapsed =    4.26 s\n",
      "Iteration    34    batch    20 /    20  loss = 0.007972    elapsed =    4.25 s\n",
      "Iteration    35    batch    20 /    20  loss = 0.007974    elapsed =    4.38 s\n",
      "Iteration    36    batch    20 /    20  loss = 0.009592    elapsed =    4.29 s\n",
      "Iteration    37    batch    20 /    20  loss = 0.007997    elapsed =    4.41 s\n",
      "Iteration    38    batch    20 /    20  loss = 0.006810    elapsed =    4.31 s\n",
      "Iteration    39    batch    20 /    20  loss = 0.007355    elapsed =    4.28 s\n",
      "Iteration    40    batch    20 /    20  loss = 0.007240    elapsed =    4.30 s\n",
      "Iteration    41    batch    20 /    20  loss = 0.006603    elapsed =    4.31 s\n",
      "Iteration    42    batch    20 /    20  loss = 0.006500    elapsed =    4.30 s\n",
      "Iteration    43    batch    20 /    20  loss = 0.007103    elapsed =    4.32 s\n",
      "Iteration    44    batch    20 /    20  loss = 0.007056    elapsed =    4.28 s\n",
      "Iteration    45    batch    20 /    20  loss = 0.006700    elapsed =    4.26 s\n",
      "Iteration    46    batch    20 /    20  loss = 0.006050    elapsed =    4.28 s\n",
      "Iteration    47    batch    20 /    20  loss = 0.005975    elapsed =    4.28 s\n",
      "Iteration    48    batch    20 /    20  loss = 0.005912    elapsed =    4.26 s\n",
      "Iteration    49    batch    20 /    20  loss = 0.006138    elapsed =    4.27 s\n",
      "Iteration    50    batch    20 /    20  loss = 0.006818    elapsed =    4.26 s\n",
      "Iteration    51    batch    20 /    20  loss = 0.007026    elapsed =    4.25 s\n",
      "Iteration    52    batch    20 /    20  loss = 0.005663    elapsed =    4.25 s\n",
      "Iteration    53    batch    20 /    20  loss = 0.005579    elapsed =    4.28 s\n",
      "Iteration    54    batch    20 /    20  loss = 0.006161    elapsed =    4.26 s\n",
      "Iteration    55    batch    20 /    20  loss = 0.006436    elapsed =    4.25 s\n",
      "Iteration    56    batch    20 /    20  loss = 0.005252    elapsed =    4.27 s\n",
      "Iteration    57    batch    20 /    20  loss = 0.005840    elapsed =    4.34 s\n",
      "Iteration    58    batch    20 /    20  loss = 0.005505    elapsed =    4.35 s\n",
      "Iteration    59    batch    20 /    20  loss = 0.005335    elapsed =    4.45 s\n",
      "Iteration    60    batch    20 /    20  loss = 0.005048    elapsed =    4.37 s\n",
      "Iteration    61    batch    20 /    20  loss = 0.005355    elapsed =    4.33 s\n",
      "Iteration    62    batch    20 /    20  loss = 0.005350    elapsed =    4.32 s\n",
      "Iteration    63    batch    20 /    20  loss = 0.005893    elapsed =    4.33 s\n",
      "Iteration    64    batch    20 /    20  loss = 0.005755    elapsed =    4.28 s\n",
      "Iteration    65    batch    20 /    20  loss = 0.005097    elapsed =    4.30 s\n",
      "Iteration    66    batch    20 /    20  loss = 0.004980    elapsed =    4.32 s\n",
      "Iteration    67    batch    20 /    20  loss = 0.005581    elapsed =    4.30 s\n",
      "Iteration    68    batch    20 /    20  loss = 0.005598    elapsed =    4.28 s\n",
      "Iteration    69    batch    20 /    20  loss = 0.004801    elapsed =    4.29 s\n",
      "Iteration    70    batch    20 /    20  loss = 0.004823    elapsed =    4.34 s\n",
      "Iteration    71    batch    20 /    20  loss = 0.004865    elapsed =    4.40 s\n",
      "Iteration    72    batch    20 /    20  loss = 0.004978    elapsed =    4.41 s\n",
      "Iteration    73    batch    20 /    20  loss = 0.004351    elapsed =    4.39 s\n",
      "Iteration    74    batch    20 /    20  loss = 0.004312    elapsed =    4.47 s\n",
      "Iteration    75    batch    20 /    20  loss = 0.004558    elapsed =    4.43 s\n",
      "Iteration    76    batch    20 /    20  loss = 0.005000    elapsed =    4.36 s\n",
      "Iteration    77    batch    20 /    20  loss = 0.005060    elapsed =    4.33 s\n",
      "Iteration    78    batch    20 /    20  loss = 0.004362    elapsed =    4.34 s\n",
      "Iteration    79    batch    20 /    20  loss = 0.004537    elapsed =    4.32 s\n",
      "Iteration    80    batch    20 /    20  loss = 0.004462    elapsed =    4.29 s\n",
      "Iteration    81    batch    20 /    20  loss = 0.004371    elapsed =    4.25 s\n",
      "Iteration    82    batch    20 /    20  loss = 0.004200    elapsed =    4.29 s\n",
      "Iteration    83    batch    20 /    20  loss = 0.004163    elapsed =    4.28 s\n",
      "Iteration    84    batch    20 /    20  loss = 0.004836    elapsed =    4.26 s\n",
      "Iteration    85    batch    20 /    20  loss = 0.005557    elapsed =    4.25 s\n",
      "Iteration    86    batch    20 /    20  loss = 0.004636    elapsed =    4.26 s\n",
      "Iteration    87    batch    20 /    20  loss = 0.004201    elapsed =    4.28 s\n",
      "Iteration    88    batch    20 /    20  loss = 0.005022    elapsed =    4.27 s\n",
      "Iteration    89    batch    20 /    20  loss = 0.004152    elapsed =    4.26 s\n",
      "Iteration    90    batch    20 /    20  loss = 0.004000    elapsed =    4.23 s\n",
      "Iteration    91    batch    20 /    20  loss = 0.004002    elapsed =    4.25 s\n",
      "Iteration    92    batch    20 /    20  loss = 0.004253    elapsed =    4.25 s\n",
      "Iteration    93    batch    20 /    20  loss = 0.003842    elapsed =    4.34 s\n",
      "Iteration    94    batch    20 /    20  loss = 0.003804    elapsed =    4.40 s\n",
      "Iteration    95    batch    20 /    20  loss = 0.003980    elapsed =    4.42 s\n",
      "Iteration    96    batch    20 /    20  loss = 0.003903    elapsed =    4.44 s\n",
      "Iteration    97    batch    20 /    20  loss = 0.005403    elapsed =    4.40 s\n",
      "Iteration    98    batch    20 /    20  loss = 0.004540    elapsed =    4.43 s\n",
      "Iteration    99    batch    20 /    20  loss = 0.003968    elapsed =    4.36 s\n",
      "Iteration   100    batch    20 /    20  loss = 0.003886    elapsed =    4.48 s\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "n_batches = int(train_size / batch_size)\n",
    "for i in range(max_iter):\n",
    "    start_time = time.time()\n",
    "    loss_cum = torch.tensor(0.)\n",
    "    for j,data in enumerate(train_dataloader):\n",
    "        print(f\"Iteration {i+1:5d}    batch {j+1:5d} / {n_batches:5d}\", end=\"\\r\", flush=True)\n",
    "        data = tg.data.Batch.from_data_list(data)\n",
    "        data.to(device)\n",
    "        output = model(data.x, data.edge_index, data.edge_attr, n_norm=n_norm)\n",
    "        loss = loss_function(output, data)\n",
    "        loss_cum += loss\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    end_time = time.time()\n",
    "    elasped_time = end_time - start_time\n",
    "    print(f\"Iteration {i+1:5d}    batch {j+1:5d} / {n_batches:5d}  loss = {loss_cum.data / (j+1):7.6f}    elapsed = {elasped_time:7.2f} s\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch   100 /   100\n",
      "Overall loss is 0.004969.  Evaluation took 6.06 s.\n"
     ]
    }
   ],
   "source": [
    "# test the model as it now\n",
    "torch.cuda.empty_cache()\n",
    "model.to(device)\n",
    "n_batches = int(test_size / batch_size)\n",
    "start_time = time.time()\n",
    "\n",
    "predictions = []\n",
    "observations = []\n",
    "\n",
    "loss_cum = torch.tensor(0.)\n",
    "for j,data in enumerate(test_dataloader):\n",
    "    print(f\"batch {j+1:5d} / {n_batches:5d}\", end=\"\\r\", flush=True)\n",
    "    data = tg.data.Batch.from_data_list(data)\n",
    "    data.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, data.edge_index, data.edge_attr, n_norm=n_norm)\n",
    "        predictions_this_batch = output.reshape((batch_size,n_atoms)).cpu().numpy()\n",
    "        observations_this_batch = data.y.reshape((batch_size,n_atoms)).cpu().numpy()\n",
    "        predictions.append(predictions_this_batch)\n",
    "        observations.append(observations_this_batch)\n",
    "        loss = loss_function(output, data)\n",
    "    loss_cum += loss\n",
    "loss_cum = loss_cum/(j+1)\n",
    "end_time = time.time()\n",
    "elasped_time = end_time - start_time\n",
    "print(f\"\\nOverall loss is {loss_cum:.6f}.  Evaluation took {elasped_time:.2f} s.\")\n",
    "predictions = np.concatenate(predictions)\n",
    "observations = np.concatenate(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "def undo_scaling(v):\n",
    "    return v * stdevs + means\n",
    "    #return v * widths + isotropic_shieldings\n",
    "unscaled_predictions = undo_scaling(predictions)\n",
    "unscaled_observations = undo_scaling(observations)\n",
    "residuals = unscaled_predictions - unscaled_observations\n",
    "print(np.shape(residuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "relevant_atomic_numbers = [1, 6]  \n",
    "relevant_atom_index = [i for i, atom_number in enumerate(atomic_numbers)\n",
    "                               if atom_number in relevant_atomic_numbers]\n",
    "print(relevant_atom_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C3</th>\n",
       "      <th>H4</th>\n",
       "      <th>H5</th>\n",
       "      <th>H6</th>\n",
       "      <th>C7</th>\n",
       "      <th>H8</th>\n",
       "      <th>H9</th>\n",
       "      <th>H10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.5741</td>\n",
       "      <td>0.2285</td>\n",
       "      <td>-0.0594</td>\n",
       "      <td>-0.0581</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>-0.2391</td>\n",
       "      <td>-0.0267</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.7376</td>\n",
       "      <td>-0.0433</td>\n",
       "      <td>-0.0425</td>\n",
       "      <td>-0.0234</td>\n",
       "      <td>-0.0076</td>\n",
       "      <td>-0.2058</td>\n",
       "      <td>-0.0668</td>\n",
       "      <td>-0.0184</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3324</td>\n",
       "      <td>-0.2465</td>\n",
       "      <td>-0.0154</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0147</td>\n",
       "      <td>-0.8282</td>\n",
       "      <td>-0.0572</td>\n",
       "      <td>-0.0630</td>\n",
       "      <td>-0.0416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.9387</td>\n",
       "      <td>0.6035</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>-0.0075</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>-0.0066</td>\n",
       "      <td>-0.0563</td>\n",
       "      <td>0.0416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2970</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>-0.0202</td>\n",
       "      <td>-0.8104</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.0268</td>\n",
       "      <td>-0.0662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C1      C3      H4      H5      H6      C7      H8      H9     H10\n",
       "0 -1.5741  0.2285 -0.0594 -0.0581  0.1207 -0.2391 -0.0267  0.0043  0.0718\n",
       "1 -0.7376 -0.0433 -0.0425 -0.0234 -0.0076 -0.2058 -0.0668 -0.0184  0.0018\n",
       "2  0.3324 -0.2465 -0.0154  0.0007 -0.0147 -0.8282 -0.0572 -0.0630 -0.0416\n",
       "3 -0.9387  0.6035  0.0082 -0.0075 -0.0343  0.1417 -0.0066 -0.0563  0.0416\n",
       "4  0.2970  0.6079  0.1002  0.0320 -0.0202 -0.8104  0.0119 -0.0268 -0.0662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('precision',4)\n",
    "df = pd.DataFrame(residuals, columns = [ f\"{j}{i+1}\" for i,j in enumerate(atomic_symbols) ] )\n",
    "df = df.iloc[:,relevant_atom_index].copy()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3,1,sharex='col',sharey='col',figsize=(12,6))\n",
    "bins = np.linspace(-4,4,100)\n",
    "def plot(where, what):\n",
    "    mean = what.mean()\n",
    "    RMSE = np.sqrt(what.pow(2).mean())\n",
    "    axs[where].hist(what, bins=bins, label=f\"{what.name} : mean = {mean:.2f}, RMSE = {RMSE:.2f}\")\n",
    "    axs[where].legend(loc='upper right')\n",
    "plot(0,df.C1)\n",
    "plot(1,df.C3)\n",
    "plot(2,df.C7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(6,1,sharex='col',sharey='col',figsize=(12,9))\n",
    "bins = np.linspace(-0.4,0.4,100)\n",
    "def plot(where, what):\n",
    "    mean = what.mean()\n",
    "    RMSE = np.sqrt(what.pow(2).mean())\n",
    "    axs[where].hist(what, bins=bins, label=f\"{what.name} : mean = {mean:.4f}, RMSE = {RMSE:.4f}\")\n",
    "    axs[where].legend(loc='upper right')\n",
    "plot(0,df.H4)\n",
    "plot(1,df.H5)\n",
    "plot(2,df.H6)\n",
    "plot(3,df.H8)\n",
    "plot(4,df.H9)\n",
    "plot(5,df.H10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
