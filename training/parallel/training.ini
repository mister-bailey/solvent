[general]
project = Solvent
device = cuda
# GPUs > 1 tries to use that many GPUs in DistributedDataParallel
# 0 < GPUs < 1 tries to use that fraction of the total GPUs
GPUs = 2
# If parallel = True/False is omitted, will infer from number of GPUs
#parallel = 

all_elements = C,H,N,O,S,F,Cl
relevant_elements = C,H

[data]
# source = SQL, hdf5 / hdf5_1 (newer file format), hdf5_0 (older file format)
source = SQL
# hdf5_filenames = data/dataset_*.hdf5
testing_size = 1000
training_size = 80000
test_train_shuffle = test_train_shuffle.pt
# randomize defaults to True
#randomize = False
# get_from_start defaults to False
#get_from_start = True
# multi_jiggle_data defaults to False
#multi_jiggle_data = True
#jiggles_per_molecule = 10

batch_preload = 2

n_molecule_processors = 1
molecule_queue_cap = 1000
example_queue_cap = 1000
batch_queue_cap = 1000

sql_fetch_size = 1000

[connect_params]
connect_params.ini

[model]
muls =   [4,5,6]
lmaxes = [3,2,1]
max_radius = 5.0
number_of_basis = 20
radial_h = 20
radial_layers = 4
n_norm = 18.0
#n_norm = 14.0
batch_norm = False
batch_norm_momentum = .02      

[training]
n_epochs = 200
# 3:30:03 = three hours, thirty minutes, three seconds
time_limit = 100:00:00
batch_size = 50
learning_rate = 3e-3   
testing_interval = 50
save_interval = 50
save_prefix = checkpoints/test_job
num_checkpoints = 5
resume = False
use_wandb = False

[wandb]
wandb.ini

[affine_correction]
# if correct = False, don't apply the correction
correct = True
# a, b --> ax + b
H = (1.004785704, -0.2470275345)
C = (1.007242827, -2.121760465)

[symbols_numbers_dict]
H = 1
C = 6
N = 7
O = 8
S = 16
F = 9
Cl = 17
