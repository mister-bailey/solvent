{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import *\n",
    "import torch\n",
    "import e3nn\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    'network': 'GatedConvParityNetwork', \n",
    "    'conv': 'Convolution',\n",
    "    'Rs_in': [(3, 0, 1)], 'Rs_out': [(1, 0, 1)],\n",
    "    'mul': 10, 'lmax': 2, 'layers': 5,\n",
    "    'max_radius': 2.,  # From dataset\n",
    "    'number_of_basis': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_from_kwargs(model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('acetone/acetone_5000_s2_small_then_large_batch.torch', model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38.1470) tensor(132.1694)\n"
     ]
    }
   ],
   "source": [
    "# read perturbed data\n",
    "with h5py.File(\"acetone/acetone-b3lyp_d3bj-631gd-gas-NMR-pcSseg_1.hdf5\", \"r\") as h5:\n",
    "    geoms_and_shieldings = np.array(h5.get(\"data\"))\n",
    "    \n",
    "shielding = torch.tensor(geoms_and_shieldings[:, :, 3], dtype=torch.float64).unsqueeze(-1)\n",
    "shielding_mean, shielding_std = shielding.mean(), shielding.std()\n",
    "print(shielding_mean, shielding_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "dataset = torch.load('acetone/acetone_geo/acetone_geometric_dataset_2499.torch')\n",
    "dataset_2 = torch.load('acetone/acetone_geo/acetone_geometric_dataset_4999.torch')\n",
    "dataloader = tg.data.DataListLoader(dataset + dataset_2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch_size_eval = 32\n",
    "\n",
    "test_dataset = torch.load('acetone/acetone_geo/acetone_geometric_dataset_7499.torch')\n",
    "test_dataloader = tg.data.DataListLoader(test_dataset, batch_size=batch_size_eval)\n",
    "\n",
    "test_dataset_2 = torch.load('acetone/acetone_geo/acetone_geometric_dataset_12499.torch')\n",
    "test_dataloader_2 = tg.data.DataListLoader(test_dataset_2, batch_size=batch_size_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff = evaluate(model, dataloader, [loss_fn_mse, loss_fn_mae], 'cuda:1', 5)\n",
    "stuff = evaluate(model, test_dataloader, [loss_fn_mse, loss_fn_mae], 'cuda:1', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE, MAE in ppm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([17763.4309,    76.9878])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('MSE, MAE in ppm')\n",
    "stuff.cpu() * torch.tensor([shielding_std ** 2, shielding_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(132.1694)\n"
     ]
    }
   ],
   "source": [
    "print(shielding_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(132.1694)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-0ebcac2f18c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshielding_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trial_save_small_fresh.torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_kwargs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/GitHubRepos/solvent/training/training_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, dataloader, test_dataloader, iter, device, n_norm, scale_loss)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mloss_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn_mae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for results in train(model, optimizer, dataloader, test_dataloader, device=\"cuda:1\", scale_loss=shielding_std):\n",
    "    with open('trial_save_small_fresh.torch', 'wb') as f:\n",
    "        results['model_kwargs'] = model_kwargs\n",
    "        torch.save(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = torch.load('acetone/acetone_geo/acetone_geometric_dataset_2499.torch')\n",
    "dataset_2 = torch.load('acetone/acetone_geo/acetone_geometric_dataset_4999.torch')\n",
    "dataloader = tg.data.DataListLoader(dataset + dataset_2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch_size_eval = 32\n",
    "\n",
    "test_dataset = torch.load('acetone/acetone_geo/acetone_geometric_dataset_7499.torch')\n",
    "test_dataloader = tg.data.DataListLoader(test_dataset, batch_size=batch_size_eval)\n",
    "\n",
    "test_dataset_2 = torch.load('acetone/acetone_geo/acetone_geometric_dataset_12499.torch')\n",
    "test_dataloader_2 = tg.data.DataListLoader(test_dataset_2, batch_size=batch_size_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.state_dict()\n",
    "# optimizer.load_state_dict(torch.load('trial_save_small_fresh_then_large_3.torch')['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(132.1694)\n",
      "0\n",
      "0 0.023256438494325772 0.06758774281502303\n",
      "1\n",
      "1 0.024299281997717435 0.10878588771268155\n",
      "2\n",
      "2 0.06089909779102471 0.13667444588613611\n",
      "3\n",
      "3 0.031067039163834582 0.11077813202038372\n",
      "4\n",
      "4 0.020992056336723554 0.07819750832269377\n",
      "6\n",
      "6 0.03315900033748473 0.09038669058420604\n",
      "8\n",
      "8 0.04377081040214497 0.10746706677435931\n",
      "10\n",
      "10 0.008875907741764251 0.07398536610897587\n",
      "13\n",
      "13 0.015275169531678692 0.07669201796318766\n",
      "16\n",
      "16 0.019881993784602547 0.09188974737110242\n",
      "20\n",
      "20 0.003872629902721232 0.04662992818969591\n",
      "24\n",
      "24 0.03303993555847925 0.13614711336262067\n",
      "28\n",
      "28 0.020550604682463922 0.08464845198598286\n",
      "33\n",
      "33 0.05209700788139679 0.1399424574293314\n",
      "38\n",
      "38 0.01578286659632377 0.07969935404991953\n",
      "43\n",
      "43 0.016564069675294026 0.08187145729249747\n",
      "48\n",
      "48 0.012948603669968767 0.07056699742493842\n",
      "53\n",
      "53 0.03197495904109956 0.0990769836184005\n",
      "58\n",
      "58 0.03821668914527086 0.0998475685185112\n",
      "63\n",
      "63 0.09624980110292763 0.16876971585625913\n",
      "68\n",
      "68 0.018231170827573886 0.07392675479664505\n",
      "73\n",
      "73 0.08650278999442233 0.10610210424690268\n",
      "78\n",
      "78 0.04115222301883873 0.12680462854221983\n",
      "83\n",
      "83 0.0406361703442037 0.15280499516904536\n",
      "88\n",
      "88 0.01782254453317994 0.10690024223166757\n",
      "93\n",
      "93 0.031142773286843076 0.09139214388073591\n",
      "98\n",
      "98 0.051605455525687315 0.10825157145981973\n"
     ]
    }
   ],
   "source": [
    "for results in train(model, optimizer, dataloader, test_dataloader, device=\"cuda:1\", scale_loss=shielding_std):\n",
    "    with open('trial_save_small_fresh_then_large_4.torch', 'wb') as f:\n",
    "        results['model_kwargs'] = model_kwargs\n",
    "        results['optimizer_state_dict'] = optimizer.state_dict()\n",
    "        torch.save(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved = torch.load('trial_save.torch')\n",
    "# saved = torch.load('trial_save_small.torch')\n",
    "# saved = torch.load('trial_save_small_fresh_then_large.torch')\n",
    "# saved = torch.load('trial_save_small_fresh_then_large_2.torch')\n",
    "# saved = torch.load('trial_save_small_fresh_then_large_3.torch')\n",
    "saved = torch.load('trial_save_small_fresh_then_large_4.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 98,\n",
       " 'wall': 7250.098932480905,\n",
       " 'batch': {'loss': 0.051605455525687315, 'mean_abs': 0.10825157145981973},\n",
       " 'test': {'loss': tensor(0.0323, device='cuda:1'),\n",
       "  'mean_abs': tensor(0.0934, device='cuda:1')},\n",
       " 'train': {'loss': tensor(0.0205, device='cuda:1'),\n",
       "  'mean_abs': tensor(0.0809, device='cuda:1')}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved['dynamics'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
