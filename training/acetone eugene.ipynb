{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import e3nn\n",
    "import e3nn.point.data_helpers as dh \n",
    "from training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Quadro M4000\n",
      "True\n",
      "10.1\n"
     ]
    }
   ],
   "source": [
    "# make sure CUDA is available\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "device = \"cuda\"\n",
    "#torch.rand(10).to(device)\n",
    "#torch.rand(10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 8 6 1 1 1 6 1 1 1]\n",
      "[ -20.1123 -337.7406  159.0655   29.4662   29.4664   29.7726  159.0733\n",
      "   29.4659   29.4658   29.773 ]\n"
     ]
    }
   ],
   "source": [
    "# read stationary data\n",
    "with h5py.File(\"acetone/acetone-b3lyp_d3bj-631gd-gas-equilibrium_geometry.hdf5\", \"r\") as h5:\n",
    "    atomic_numbers = np.array(h5.get(\"atomic_numbers\"))\n",
    "    isotropic_shieldings = np.array(h5.get(\"isotropic_shieldings\"))\n",
    "print(atomic_numbers)\n",
    "print(isotropic_shieldings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 10, 4)\n"
     ]
    }
   ],
   "source": [
    "# read perturbed data\n",
    "with h5py.File(\"acetone/acetone-b3lyp_d3bj-631gd-gas-NMR-pcSseg_1.hdf5\", \"r\") as h5:\n",
    "    geoms_and_shieldings = np.array(h5.get(\"data\"))\n",
    "print(np.shape(geoms_and_shieldings))\n",
    "geometries = geoms_and_shieldings[:,:,:3]\n",
    "shieldings = geoms_and_shieldings[:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data on a per-site basis\n",
    "# this is extreme, but let's see how well we can do with this\n",
    "means = np.mean(shieldings, axis=0)\n",
    "stdevs = np.std(shieldings, axis=0)\n",
    "shieldings = (shieldings-means)/stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will undo scaling so we can recover the absolute shieldings from predictions\n",
    "def undo_scaling(v):\n",
    "    return v * stdevs + means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one-hot features\n",
    "one_hots = pd.get_dummies(atomic_numbers)\n",
    "one_hots = one_hots.to_numpy()\n",
    "\n",
    "# get some shapes\n",
    "n_examples = geometries.shape[0]\n",
    "n_atoms_per_example = geometries.shape[1]\n",
    "n_one_hots = one_hots.shape[1]\n",
    "\n",
    "# features are just one-hots, so repeat the same one-hots for every training example\n",
    "desired_shape = (n_examples, n_atoms_per_example, n_one_hots)\n",
    "features = np.zeros(desired_shape)\n",
    "features[:] = one_hots              # broadcast one_hots into every row along axis 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features are one-hots for every atom,\n",
    "# so this is (number of one_hots, rank zero tensor, even parity)\n",
    "Rs_in = [(n_one_hots,0,1)]\n",
    "\n",
    "# we are outputing one scalar for every atom\n",
    "# so this is (one, rank zero tensor, even parity)\n",
    "Rs_out = [(1,0,1)]\n",
    "\n",
    "# maximum extent of radial basis functions in Angstroms\n",
    "max_radius = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.DataNeighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataNeighborsSelection(dh.DataNeighbors):\n",
    "    def __init__(self, x, Rs_in, pos, r_max, atomic_numbers, relevant_atomic_numbers=None, self_interaction=True, **kwargs):\n",
    "        if atomic_numbers is None:\n",
    "            raise ValueError(\"atomic_numbers must be defined\")\n",
    "        if relevant_atomic_numbers is None:\n",
    "            relevant_atomic_numbers = [1, 6]  \n",
    "        relevant_atomic_number_index = [i for i, atom_number for enumerate(atomic_numbers) \n",
    "                                        if atom_number in relevant_atomic_numbers]\n",
    "        \n",
    "        super().__init__(self, x, Rs_in, pos, r_max, atomic_numbers=atomic_numbers, \n",
    "                         relevant_atomic_number_index=relevant_atomic_number_index,\n",
    "                         self_interaction=self_interaction, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a subset of the data to a .torch file\n",
    "# precompute the relevant neighbors\n",
    "def save_dataset(geometry_subset, shielding_subset, feature_subset, output_filename):\n",
    "    dataset = []\n",
    "    n_to_save = len(geometry_subset)\n",
    "    print(f\"Preprocessing for {output_filename}:\")\n",
    "    for i,(g,s,f) in enumerate(zip(geometry_subset, shielding_subset, feature_subset)):\n",
    "        g,s,f = torch.tensor(g, dtype=torch.float64), torch.tensor(s, dtype=torch.float64), torch.tensor(f, dtype=torch.float64)\n",
    "        data = dh.DataNeighborsSelection(x=f, Rs_in=Rs_in, pos=g, r_max=max_radius, \n",
    "                                         atomic_numbers=atomic_numbers, relevant_atomic_numbers=relevant_atomic_numbers,\n",
    "                                         y=s, Rs_out=Rs_out)\n",
    "        dataset.append(data)\n",
    "        if (i+1) % 100 == 0 or i == n_to_save - 1:\n",
    "            print(f\"{i+1:10d} of {n_to_save:10d}...\", end=\"\\r\", flush=True)\n",
    "    print(\"\\nWriting to disk...\", end=\"\", flush=True)\n",
    "    torch.save(dataset, output_filename)\n",
    "    print(f\"done.  Saved {len(dataset)} records.\")\n",
    "    \n",
    "# splits the dataset randomly into training and test sets\n",
    "# train_size = # number of training examples\n",
    "# test_size = # number of test examples\n",
    "# prefix = filenames will start with this string\n",
    "# random_state = for reproducible splits\n",
    "def split_and_save(train_size, test_size, prefix, random_state):\n",
    "    assert train_size + test_size <= n_examples\n",
    "    # [ training_geometries, training_shieldings, training_features,\n",
    "    #   testing_geometries, testing_shieldings, testing_features     ]\n",
    "    splitting = train_test_split(geometries, shieldings, features,\n",
    "                                 test_size = test_size, train_size = train_size,\n",
    "                                 random_state = random_state, shuffle = True)\n",
    "    save_dataset(*splitting[::2], f\"{prefix}-train.torch\")\n",
    "    save_dataset(*splitting[1::2], f\"{prefix}-test.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing for acetone-split1-train.torch:\n",
      "       500 of        500...\n",
      "Writing to disk...done.  Saved 500 records.\n",
      "Preprocessing for acetone-split1-test.torch:\n",
      "      5000 of       5000...\n",
      "Writing to disk...done.  Saved 5000 records.\n"
     ]
    }
   ],
   "source": [
    "train_size = 500\n",
    "test_size = 5000\n",
    "split_and_save(train_size, test_size, \"acetone-split1\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = torch.load(\"acetone-split1-train.torch\")\n",
    "dataset2 = torch.load(\"acetone-split1-test.torch\")\n",
    "batch_size = 5\n",
    "train_dataloader = tg.data.DataListLoader(dataset1, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = tg.data.DataListLoader(dataset2, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE loss function for this system\n",
    "# only incorporate elements of interest\n",
    "relevant_atomic_numbers = {1,6}\n",
    "def loss_function_generator(atomic_numbers):\n",
    "    indices = []\n",
    "    for i,atomic_number in enumerate(atomic_numbers):\n",
    "        if atomic_number in relevant_atomic_numbers:\n",
    "            indices.append(i)\n",
    "    indices = indices * batch_size\n",
    "            \n",
    "    def loss_function(x,y):\n",
    "        error = (x-y)[indices]**2.0\n",
    "        return error.mean()\n",
    "    \n",
    "    return loss_function\n",
    "loss_function = loss_function_generator(atomic_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network architecture\n",
    "model_kwargs = {\n",
    "    'network': 'GatedConvParityNetwork', \n",
    "    'conv': 'Convolution',\n",
    "    'Rs_in': Rs_in,            # shape of inputs\n",
    "    'Rs_out': Rs_out,          # shape of outputs\n",
    "    'mul': 5,                 # how many copies of each tensor at each layer\n",
    "    'lmax': 2,                 # maximum angular momentum\n",
    "    'layers': 3,               # number of layers\n",
    "    'max_radius': max_radius,  # radial kernel will extend out this far\n",
    "    'number_of_basis': 10,     # number of Gaussians in radial kernel\n",
    "}\n",
    "model = model_from_kwargs(model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 1.0489.  Took 31.72 seconds.\n"
     ]
    }
   ],
   "source": [
    "# test the model as it now\n",
    "# n_norm is average number of convolution neighbors per atom\n",
    "model.to(device)\n",
    "start_time = time.time()\n",
    "losses = evaluate(model, test_dataloader, [loss_function], device, n_norm=5)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Loss is {losses[0].data:.4f}.  Took {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "learning_rate = 3e-3\n",
    "opt = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "max_iter = 100       \n",
    "n_norm = 5           # n_norm is average number of convolution neighbors per atom\n",
    "n_batches = int(train_size / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration     1    batch   100 /   100  loss =  1.0282    elapsed =    4.80 s\n",
      "Iteration     2    batch   100 /   100  loss =  1.4504    elapsed =    4.67 s\n",
      "Iteration     3    batch    30 /   100\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-b6dfd1770225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_data_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/anaconda2/envs/solvent2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/anaconda2/envs/solvent2/lib/python3.8/site-packages/e3nn/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/anaconda2/envs/solvent2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/anaconda2/envs/solvent2/lib/python3.8/site-packages/e3nn/point/message_passing.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, edge_index, edge_r, size, n_norm)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/anaconda2/envs/solvent2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/anaconda2/envs/solvent2/lib/python3.8/site-packages/e3nn/kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, r, r_eps, custom_backward)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mkernel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKernelFn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRs_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_of_l_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mkernel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_fn_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRs_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_of_l_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# (2) Case r = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/anaconda2/envs/solvent2/lib/python3.8/site-packages/e3nn/kernel.py\u001b[0m in \u001b[0;36mkernel_fn_forward\u001b[0;34m(Y, R, norm_coef, Rs_in, Rs_out, selection_rule, set_of_l_filters)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# note: The multiplication with `sub_R` could also be done outside of the for loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mK\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnorm_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ijk,zk,zuv->zuivj\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_R\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch, mul_out, m_out, mul_in, m_in]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/anaconda2/envs/solvent2/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *operands)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# the old interface of passing the operands as one list argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0moperands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "for i in range(max_iter):\n",
    "    start_time = time.time()\n",
    "    for j,data in enumerate(train_dataloader):\n",
    "        print(f\"Iteration {i+1:5d}    batch {j+1:5d} / {n_batches:5d}\", end=\"\\r\", flush=True)\n",
    "        data = tg.data.Batch.from_data_list(data)\n",
    "        data.to(device)\n",
    "        output = model(data.x, data.edge_index, data.edge_attr, n_norm=n_norm)\n",
    "        loss = loss_function(output, data.y)\n",
    "    end_time = time.time()\n",
    "    elasped_time = end_time - start_time\n",
    "    print(f\"Iteration {i+1:5d}    batch {j+1:5d} / {n_batches:5d}  loss = {loss.data:7.4f}    elapsed = {elasped_time:7.2f} s\")\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model as it now\n",
    "# n_norm is average number of convolution neighbors per atom\n",
    "losses = evaluate(model, test_dataloader, [loss_function], device, n_norm=5)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shielding = torch.tensor(geoms_and_shieldings[:, :, 3], dtype=torch.float64).unsqueeze(-1)\n",
    "shielding_mean, shielding_std = shielding.mean(), shielding.std()\n",
    "print(shielding_mean, shielding_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_from_kwargs(model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('acetone/acetone_5000_s2_small_then_large_batch.torch', model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38.1470) tensor(132.1694)\n"
     ]
    }
   ],
   "source": [
    "# read perturbed data\n",
    "with h5py.File(\"acetone/acetone-b3lyp_d3bj-631gd-gas-NMR-pcSseg_1.hdf5\", \"r\") as h5:\n",
    "    geoms_and_shieldings = np.array(h5.get(\"data\"))\n",
    "    \n",
    "shielding = torch.tensor(geoms_and_shieldings[:, :, 3], dtype=torch.float64).unsqueeze(-1)\n",
    "shielding_mean, shielding_std = shielding.mean(), shielding.std()\n",
    "print(shielding_mean, shielding_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "dataset = torch.load('acetone/acetone_geo/acetone_geometric_dataset_2499.torch')\n",
    "dataset_2 = torch.load('acetone/acetone_geo/acetone_geometric_dataset_4999.torch')\n",
    "dataloader = tg.data.DataListLoader(dataset + dataset_2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch_size_eval = 32\n",
    "\n",
    "test_dataset = torch.load('acetone/acetone_geo/acetone_geometric_dataset_7499.torch')\n",
    "test_dataloader = tg.data.DataListLoader(test_dataset, batch_size=batch_size_eval)\n",
    "\n",
    "test_dataset_2 = torch.load('acetone/acetone_geo/acetone_geometric_dataset_12499.torch')\n",
    "test_dataloader_2 = tg.data.DataListLoader(test_dataset_2, batch_size=batch_size_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff = evaluate(model, dataloader, [loss_fn_mse, loss_fn_mae], 'cuda:1', 5)\n",
    "stuff = evaluate(model, test_dataloader, [loss_fn_mse, loss_fn_mae], 'cuda:1', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE, MAE in ppm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([17763.4309,    76.9878])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('MSE, MAE in ppm')\n",
    "stuff.cpu() * torch.tensor([shielding_std ** 2, shielding_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(132.1694)\n"
     ]
    }
   ],
   "source": [
    "print(shielding_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(132.1694)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-0ebcac2f18c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshielding_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trial_save_small_fresh.torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_kwargs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/GitHubRepos/solvent/training/training_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, dataloader, test_dataloader, iter, device, n_norm, scale_loss)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mloss_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn_mae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for results in train(model, optimizer, dataloader, test_dataloader, device=\"cuda:1\", scale_loss=shielding_std):\n",
    "    with open('trial_save_small_fresh.torch', 'wb') as f:\n",
    "        results['model_kwargs'] = model_kwargs\n",
    "        torch.save(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = torch.load('acetone/acetone_geo/acetone_geometric_dataset_2499.torch')\n",
    "dataset_2 = torch.load('acetone/acetone_geo/acetone_geometric_dataset_4999.torch')\n",
    "dataloader = tg.data.DataListLoader(dataset + dataset_2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "batch_size_eval = 32\n",
    "\n",
    "test_dataset = torch.load('acetone/acetone_geo/acetone_geometric_dataset_7499.torch')\n",
    "test_dataloader = tg.data.DataListLoader(test_dataset, batch_size=batch_size_eval)\n",
    "\n",
    "test_dataset_2 = torch.load('acetone/acetone_geo/acetone_geometric_dataset_12499.torch')\n",
    "test_dataloader_2 = tg.data.DataListLoader(test_dataset_2, batch_size=batch_size_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.state_dict()\n",
    "# optimizer.load_state_dict(torch.load('trial_save_small_fresh_then_large_3.torch')['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(132.1694)\n",
      "0\n",
      "0 0.023256438494325772 0.06758774281502303\n",
      "1\n",
      "1 0.024299281997717435 0.10878588771268155\n",
      "2\n",
      "2 0.06089909779102471 0.13667444588613611\n",
      "3\n",
      "3 0.031067039163834582 0.11077813202038372\n",
      "4\n",
      "4 0.020992056336723554 0.07819750832269377\n",
      "6\n",
      "6 0.03315900033748473 0.09038669058420604\n",
      "8\n",
      "8 0.04377081040214497 0.10746706677435931\n",
      "10\n",
      "10 0.008875907741764251 0.07398536610897587\n",
      "13\n",
      "13 0.015275169531678692 0.07669201796318766\n",
      "16\n",
      "16 0.019881993784602547 0.09188974737110242\n",
      "20\n",
      "20 0.003872629902721232 0.04662992818969591\n",
      "24\n",
      "24 0.03303993555847925 0.13614711336262067\n",
      "28\n",
      "28 0.020550604682463922 0.08464845198598286\n",
      "33\n",
      "33 0.05209700788139679 0.1399424574293314\n",
      "38\n",
      "38 0.01578286659632377 0.07969935404991953\n",
      "43\n",
      "43 0.016564069675294026 0.08187145729249747\n",
      "48\n",
      "48 0.012948603669968767 0.07056699742493842\n",
      "53\n",
      "53 0.03197495904109956 0.0990769836184005\n",
      "58\n",
      "58 0.03821668914527086 0.0998475685185112\n",
      "63\n",
      "63 0.09624980110292763 0.16876971585625913\n",
      "68\n",
      "68 0.018231170827573886 0.07392675479664505\n",
      "73\n",
      "73 0.08650278999442233 0.10610210424690268\n",
      "78\n",
      "78 0.04115222301883873 0.12680462854221983\n",
      "83\n",
      "83 0.0406361703442037 0.15280499516904536\n",
      "88\n",
      "88 0.01782254453317994 0.10690024223166757\n",
      "93\n",
      "93 0.031142773286843076 0.09139214388073591\n",
      "98\n",
      "98 0.051605455525687315 0.10825157145981973\n"
     ]
    }
   ],
   "source": [
    "for results in train(model, optimizer, dataloader, test_dataloader, device=\"cuda:1\", scale_loss=shielding_std):\n",
    "    with open('trial_save_small_fresh_then_large_4.torch', 'wb') as f:\n",
    "        results['model_kwargs'] = model_kwargs\n",
    "        results['optimizer_state_dict'] = optimizer.state_dict()\n",
    "        torch.save(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved = torch.load('trial_save.torch')\n",
    "# saved = torch.load('trial_save_small.torch')\n",
    "# saved = torch.load('trial_save_small_fresh_then_large.torch')\n",
    "# saved = torch.load('trial_save_small_fresh_then_large_2.torch')\n",
    "# saved = torch.load('trial_save_small_fresh_then_large_3.torch')\n",
    "saved = torch.load('trial_save_small_fresh_then_large_4.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step': 98,\n",
       " 'wall': 7250.098932480905,\n",
       " 'batch': {'loss': 0.051605455525687315, 'mean_abs': 0.10825157145981973},\n",
       " 'test': {'loss': tensor(0.0323, device='cuda:1'),\n",
       "  'mean_abs': tensor(0.0934, device='cuda:1')},\n",
       " 'train': {'loss': tensor(0.0205, device='cuda:1'),\n",
       "  'mean_abs': tensor(0.0809, device='cuda:1')}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved['dynamics'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
